{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c839821c-eee0-4c42-b616-e3771c0ca649",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983fee47-9250-4a50-a555-012e6d7e8efc",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df0e5212-f75a-4438-95bd-11d47f7a9c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c0b27f-50bf-4227-a984-c494ae2f8767",
   "metadata": {},
   "source": [
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb706108-b876-4601-bfc4-5304a0d0056c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a70b2-080a-4f77-a8bc-8fe6076a47cb",
   "metadata": {},
   "source": [
    "## Pre-process Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e853841-5e61-4f47-8ab5-498b6bce2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of all folders\n",
    "folders = '/home/jovyan/work/GitHub/convolutionalNeuralNet/'\n",
    "classes = [name for name in os.listdir(folders + 'images/temp') if os.path.isdir(os.path.join(folders + 'images/temp', name)) and name != '.ipynb_checkpoints']\n",
    "\n",
    "train_path = folders + 'images/train/'\n",
    "valid_path = folders + 'images/valid/'\n",
    "test_path = folders + 'images/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b46defc-6fb3-4468-9716-222a62d9f453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albania', 'Mexico', 'Kyrgyzstan', 'UnitedKingdom', 'UnitedStates']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a427c635-d55d-4e70-9fc9-1a8543e86410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 5 classes.\n",
      "Found 100 images belonging to 5 classes.\n",
      "Found 20 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Using the VGG16 image processing for RBG images\n",
    "# Preprocessing the training, validation, and testing images\n",
    "\n",
    "train_batches = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
    ").flow_from_directory(\n",
    "    directory=train_path,\n",
    "    target_size=(224, 224),\n",
    "    classes=classes,\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "valid_batches = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
    ").flow_from_directory(\n",
    "    directory=valid_path,\n",
    "    target_size=(224, 224),\n",
    "    classes=classes,\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "test_batches = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
    ").flow_from_directory(\n",
    "    directory=test_path,\n",
    "    target_size=(224, 224),\n",
    "    classes=classes,\n",
    "    batch_size=10,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95169789-74ce-45c5-bd4d-e58f6444b9e9",
   "metadata": {},
   "source": [
    "## Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bac4b82-9391-45e0-bd5b-03ebf55e194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(                         # Hidden layer\n",
    "        filters=32,                 # Standard value\n",
    "        kernel_size=(3, 3),         # Standard value\n",
    "        activation='relu',          # Standard activation\n",
    "        padding='same',             # No padding\n",
    "        input_shape=(224, 224, 3)   # Shape of image\n",
    "    ),\n",
    "    MaxPool2D(                      # Max pooling for dimension reduction\n",
    "        pool_size=(2, 2),           # Filter size\n",
    "        strides=2                   # Cut in half\n",
    "    ),\n",
    "    Conv2D(                         # Hidden layer\n",
    "        filters=64,                 # Increase filters as you add layers\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    ),\n",
    "    MaxPool2D(                      # Max pooling for dimension reduction\n",
    "        pool_size=(2, 2),\n",
    "        strides=2\n",
    "    ),\n",
    "    Conv2D(                         # Hidden layer\n",
    "        filters=128,\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    ),\n",
    "    MaxPool2D(                      # Max pooling for dimension reduction\n",
    "        pool_size=(2, 2),\n",
    "        strides=2\n",
    "    ),\n",
    "    Flatten(),                      # Flatten for output layer\n",
    "    Dense(                          # Output layer\n",
    "        units=len(classes),\n",
    "        activation='softmax'\n",
    "    )\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0cce3f-a6c3-4c28-95d4-bde0c66b0b5a",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "407c1f69-21ad-4bd0-8dd6-51a5bb4357a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "50/50 [==============================] - 4s 49ms/step - loss: 13.0010 - accuracy: 0.2280 - val_loss: 2.6910 - val_accuracy: 0.4300\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.4787 - accuracy: 0.5840 - val_loss: 2.2796 - val_accuracy: 0.4400\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 0.4360 - accuracy: 0.8420 - val_loss: 2.8348 - val_accuracy: 0.4000\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 0.2437 - accuracy: 0.9260 - val_loss: 2.6671 - val_accuracy: 0.4200\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 0.0635 - accuracy: 0.9880 - val_loss: 2.6272 - val_accuracy: 0.4600\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.6896 - val_accuracy: 0.5100\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.6534 - val_accuracy: 0.5100\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.7598 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.7696 - val_accuracy: 0.4900\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.8109 - val_accuracy: 0.5100\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.8029 - val_accuracy: 0.4900\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.8630 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9105 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9016 - val_accuracy: 0.4900\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.9382 - val_accuracy: 0.4900\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.0002 - val_accuracy: 0.4900\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.9366 - val_accuracy: 0.4700\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.9863 - val_accuracy: 0.4700\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 8.8538e-04 - accuracy: 1.0000 - val_loss: 3.0574 - val_accuracy: 0.4800\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 7.5833e-04 - accuracy: 1.0000 - val_loss: 3.0459 - val_accuracy: 0.4900\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 6.6301e-04 - accuracy: 1.0000 - val_loss: 3.0954 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 5.9050e-04 - accuracy: 1.0000 - val_loss: 3.0436 - val_accuracy: 0.4800\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 4.4664e-04 - accuracy: 1.0000 - val_loss: 3.0617 - val_accuracy: 0.4800\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 3.3731e-04 - accuracy: 1.0000 - val_loss: 3.0633 - val_accuracy: 0.4700\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 2.5641e-04 - accuracy: 1.0000 - val_loss: 3.0886 - val_accuracy: 0.4800\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 1.9907e-04 - accuracy: 1.0000 - val_loss: 3.0961 - val_accuracy: 0.4700\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.6339e-04 - accuracy: 1.0000 - val_loss: 3.1954 - val_accuracy: 0.4600\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.3148e-04 - accuracy: 1.0000 - val_loss: 3.1585 - val_accuracy: 0.4800\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 2s 46ms/step - loss: 1.1254e-04 - accuracy: 1.0000 - val_loss: 3.1880 - val_accuracy: 0.4600\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 9.3995e-05 - accuracy: 1.0000 - val_loss: 3.1671 - val_accuracy: 0.4700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faae21e83a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=train_batches,\n",
    "    validation_data=valid_batches,\n",
    "    epochs=30,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2de43-6131-4978-880d-50bacfa8a882",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fff6864-2ca0-4771-82ce-3f8952d2434a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/jovyan/work/GitHub/convolutionalNeuralNet/models/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(folders + 'models')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
